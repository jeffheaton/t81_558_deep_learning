{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/jeffheaton/t81_558_deep_learning/blob/master/assignments/assignment_yourname_class3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T81-558: Applications of Deep Neural Networks\n",
    "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), School of Engineering and Applied Science, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
    "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/).\n",
    "\n",
    "**Module 3 Assignment: Data Preparation in Pandas**\n",
    "\n",
    "**Student Name: Your Name**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Instructions\n",
    "\n",
    "For this assignment, you will use the **series-31** dataset.  This file contains a dataset that I generated explicitly for this semester.  You can find the CSV file on my data site, at this location: [series-31](https://data.heatonresearch.com/data/t81-558/datasets/series-31.csv). Load and summarize the data set.  You will submit this summarized dataset to the **submit** function.  See [Assignment #1](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/assignments/assignment_yourname_class1.ipynb) for details on how to submit an assignment or check that one was submitted.\n",
    "\n",
    "The RAW datafile looks something like the following:\n",
    "\n",
    "\n",
    "|time|value|\n",
    "|----|-----|\n",
    "|8/22/19 12:51|    19.19535862|\n",
    "|9/19/19 9:44|13.51954348|\n",
    "|8/26/19 14:05|9.191413297|\n",
    "|8/19/19 16:37|18.34659762|\n",
    "|9/5/19 9:18|1.349778007|\n",
    "|9/2/19 10:23|8.462216832|\n",
    "|8/23/19 15:05|17.2471252|\n",
    "|...|...|\n",
    "\n",
    "Summarize the dataset as follows:\n",
    "\n",
    "|date|starting|max|min|ending|\n",
    "|---|---|---|---|---|\n",
    "|8/19/19|17.57352208|18.46883497|17.57352208|18.46883497|\n",
    "|8/20/19|19.49660945|19.84883044|19.49660945|19.84883044|\n",
    "|8/21/19|20.0339169|20.0339169|19.92099707|19.92099707|\n",
    "|...|...|...|...|...|\n",
    "\n",
    "* There should be one row for each unique date in the data set.\n",
    "* Think of the **value** as a stock price.  You only have values during certain hours and certain days.\n",
    "* The **date** column is each of the different dates in the file.\n",
    "* The **starting** column is the first **value** of that date (has the earliest time).\n",
    "* The **max** column is the maximum **value** for that day.\n",
    "* The **min** column is the minimum **value** for that day.\n",
    "* The **ending** column is the final **value** for that day (has the latest time).\n",
    "\n",
    "You can process the **time** column either as strings or as Python **datetime**.  It may be necessary to use Pandas functions beyond those given in the class lecture.\n",
    "\n",
    "Note, you might get the following warning on the date field from the API.  You can safely ignore this warning:\n",
    "\n",
    "* Warning: The mean of column date differs from the solution file by 2010.4. (might not matter if small)\n",
    "\n",
    "Your submission triggers this warning due to the method you use to convert the time/date.  Your code is correct, whether you get this warning or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google CoLab Instructions\n",
    "\n",
    "If you are using Google CoLab, it will be necessary to mount your GDrive so that you can send your notebook during the submit process. Running the following code will map your GDrive to ```/content/drive```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "    %tensorflow_version 2.x\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Submit Function\n",
    "\n",
    "You will submit the 10 programming assignments electronically.  The following submit function can be used to do this.  My server will perform a basic check of each assignment and let you know if it sees any basic problems. \n",
    "\n",
    "**It is unlikely that should need to modify this function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# This function submits an assignment.  You can submit an assignment as much as you like, only the final\n",
    "# submission counts.  The paramaters are as follows:\n",
    "# data - Pandas dataframe output.\n",
    "# key - Your student key that was emailed to you.\n",
    "# no - The assignment class number, should be 1 through 1.\n",
    "# source_file - The full path to your Python or IPYNB file.  This must have \"_class1\" as part of its name.  \n",
    "# .             The number must match your assignment number.  For example \"_class2\" for class assignment #2.\n",
    "def submit(data,key,no,source_file=None):\n",
    "    if source_file is None and '__file__' not in globals(): raise Exception('Must specify a filename when a Jupyter notebook.')\n",
    "    if source_file is None: source_file = __file__\n",
    "    suffix = '_class{}'.format(no)\n",
    "    if suffix not in source_file: raise Exception('{} must be part of the filename.'.format(suffix))\n",
    "    with open(source_file, \"rb\") as image_file:\n",
    "        encoded_python = base64.b64encode(image_file.read()).decode('ascii')\n",
    "    ext = os.path.splitext(source_file)[-1].lower()\n",
    "    if ext not in ['.ipynb','.py']: raise Exception(\"Source file is {} must be .py or .ipynb\".format(ext))\n",
    "    r = requests.post(\"https://api.heatonresearch.com/assignment-submit\",\n",
    "        headers={'x-api-key':key}, json={'csv':base64.b64encode(data.to_csv(index=False).encode('ascii')).decode(\"ascii\"),\n",
    "        'assignment': no, 'ext':ext, 'py':encoded_python})\n",
    "    if r.status_code == 200:\n",
    "        print(\"Success: {}\".format(r.text))\n",
    "    else: print(\"Failure: {}\".format(r.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Assignment #3 Sample Code\n",
    "\n",
    "The following code provides a starting point for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# This is your student key that I emailed to you at the beginnning of the semester.\n",
    "key = \"PPboscDL2M94HCbkbvfOLakXXNy3dh5x2VV1Mlpm\"  # This is an example key and will not work.\n",
    "\n",
    "# You must also identify your source file.  (modify for your local setup)\n",
    "# file='/content/drive/My Drive/Colab Notebooks/assignment_yourname_class3.ipynb'  # Google CoLab\n",
    "# file='C:\\\\Users\\\\jeffh\\\\projects\\\\t81_558_deep_learning\\\\assignments\\\\assignment_yourname_class3.ipynb'  # Windows\n",
    "file='/Users/jheaton/projects/t81_558_deep_learning/assignments/assignment_yourname_class3.ipynb'  # Mac/Linux\n",
    "\n",
    "# Begin assignment\n",
    "\n",
    "df = pd.read_csv(\"https://data.heatonresearch.com/data/t81-558/datasets/series-31.csv\")\n",
    "df['time'] = pd.to_datetime(df['time'], errors='coerce')\n",
    "\n",
    "# Your code goes here.\n",
    "\n",
    "\n",
    "# Submit\n",
    "submit(source_file=file,data=df_submit,key=key,no=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "rga"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
