{"cells": [{"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "L2fejML3tCfv"}, "source": ["<a href=\"https://colab.research.google.com/github/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_07_3_style_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "nTYnTqOPtCfy"}, "source": ["# T81-558: Applications of Deep Neural Networks\n", "**Module 7: Generative Adversarial Networks**\n", "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n", "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/)."]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "oZIf2h_itCf0"}, "source": ["# Module 7 Material\n", "\n", "* Part 7.1: Introduction to GANS for Image and Data Generation [[Video]](https://www.youtube.com/watch?v=0QnCH6tlZgc&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](t81_558_class_07_1_gan_intro.ipynb)\n", "* Part 7.2: Implementing a GAN in Keras [[Video]](https://www.youtube.com/watch?v=T-MCludVNn4&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](t81_558_class_07_2_Keras_gan.ipynb)\n", "* **Part 7.3: Face Generation with StyleGAN and Python** [[Video]](https://www.youtube.com/watch?v=Wwwyr7cOBlU&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](t81_558_class_07_3_style_gan.ipynb)\n", "* Part 7.4: GANS for Semi-Supervised Learning in Keras [[Video]](https://www.youtube.com/watch?v=ZPewmEu7644&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](t81_558_class_07_4_gan_semi_supervised.ipynb)\n", "* Part 7.5: An Overview of GAN Research [[Video]](https://www.youtube.com/watch?v=cvCvZKvlvq4&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](t81_558_class_07_5_gan_research.ipynb)\n"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "IIRFv-IHtCf1"}, "source": ["## Warning: This Module Requires TensorFlow 1.x\n", "\n", "This module makes use of the nVidia StyleGAN2 package.  Neither StyleGAN 1.0 nor StyleGAN 2.0 currently supports TensorFlow 2.0.  Because of this incompatibility, it will be necessary to run this code with an older version of TensorFlow.  Running this notebook in this way is easiest with Google CoLab.  Because of this, I designed this module to run in Google CoLab.  It will take some modifications to if you wish to run it locally.\n", "\n", "Also, note that this module uses StyleGAN 1.0, I will soon update to 2.0."]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "4xVz_59FtCf3"}, "source": ["# Part 7.3: Face Generation with StyleGAN and Python\n", "\n", "GANs have appeared frequently in the media, showcasing their ability to generate extremely photorealistic faces.  One significant step forward for realistic face generation was nVidia StyleGAN. [[Cite:karras2019style]](https://arxiv.org/abs/1812.04948) In this module we will explore StyleGAN2, which is the second interation of this technology by nVidia. [[Cite:karras2019analyzing]](https://arxiv.org/abs/1912.04958) We will also preload weights that nVidia trained on.  This will allow us to generate high resolution photorealistic looking faces, such seen in Figure 7.STY-GAN.\n", "\n", "**Figure 7.STY-GAN: StyleGAN2 Generated Faces**\n", "![StyleGAN2 Generated Faces](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/stylegan2_images.png \"StyleGAN2 Generated Faces\")\n", "\n", "The above images were generated with StyleGAN2, using Google CoLab.  Following the instructions in this section, you will be able to create faces like this of your own.  StyleGAN2 images are usually 1,024 x 1,024 in resolution.  An example of a full resolution StyleGAN image can be [found here](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/stylegan2-hires.png). \n", "\n", "While the above images look much more realistic than images generated earlier in this course, they are not perfect.  Look at Figure 7.STYLEGAN2. There are usually a number of tell-tail signs that you are looking at a computer generated image.  One of the most obvious is usually the surreal, dream-like backgrounds.  The background does not look obviously fake, at first glance; however, upon closer inspection you usually can't quite discern exactly what a GAN generated background actually is.  Also look at the image character's left eye.  It is slightly unrealistic looking, especially near the eyelashes.\n", "\n", "Look at the following GAN face.  Can you spot any imperfections?\n", "\n", "**Figure 7.STYLEGAN2: StyleGAN2 Face**\n", "![StyleGAN2 Face](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/gan_bad.png \"StyleGAN2 Face\")\n", "\n", "* Image A demonstrates the very abstract backgrounds usually associated with a GAN generated image.\n", "* Image B exhibits issues that earrings often present for GANs. GANs sometimes have problems with symmetry, particularly earrings.\n", "* Image C contains an abstract background, as well as a highly distorted secondary image.\n", "* Image D also contains a highly distorted secondary image that might be a hand.\n", "\n", "There are a number of websites that allow you to generate GANs of your own without any software.\n", "\n", "* [This Person Does not Exist](https://www.thispersondoesnotexist.com/)\n", "* [Which Face is Real](http://www.whichfaceisreal.com/)\n", "\n", "The first site generates high resolution images of human faces.  The second site presents a quiz to see if you can detect the difference between a real and fake human faceimage.\n", "\n", "In this module you will learn to create your own StyleGAN2 pictures using Python."]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "p44L5mC-tCf4"}, "source": ["### Keras Sequence vs Functional Model API\n", "\n", "Most of the neural networks create in this course have made use of the Keras sequence object.  You might have noticed that we briefly made use of another type of neural network object for the ResNet, the Model.  These are the [two major means](https://keras.io/getting-started/functional-api-guide/) of constructing a neural network in Keras:\n", "\n", "* [Sequential](https://keras.io/getting-started/sequential-model-guide/) - Simplified interface to Keras that supports most models where the flow of information is a simple sequence from input to output. \n", "* [Keras Functional API](https://keras.io/getting-started/functional-api-guide/) - More complex interface that allows neural networks to be constructed of reused layers, multiple input layers, and supports building your own recurrent connections.\n", "\n", "It is important to point out that these are not two specific types of neural network.  Rather, they are two means of constructing neural networks in Keras.  Some types of neural network can be implemented in either, such as dense feedforward neural networks (like we used for the Iris and MPG datasets).  However, other types of neural network, like ResNet and GANs can only be used in the Functional Model API."]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "IWl5ywCjtCf5"}, "source": ["### Generating High Rez GAN Faces with Google CoLab\n", "\n", "This notebook demonstrates how to run [NVidia StyleGAN2](https://github.com/NVlabs/stylegan) inside of a Google CoLab notebook.  I suggest you use this to generate GAN faces from a pretrained model.  If you try to train your own, you will run into compute limitations of Google CoLab.\n", "\n", "Make sure to run this code on a GPU instance.  GPU is assumed.\n", "\n", "First, map your G-Drive, this is where your GANs will be written to."]}, {"cell_type": "code", "execution_count": 0, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 122}, "colab_type": "code", "id": "w2dEcHb9tCf6", "outputId": "d520720e-48e1-4112-a5c2-72457ecad017"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n", "\n", "Enter your authorization code:\n", "\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\n", "Mounted at /content/drive\n"]}], "source": ["# Run this for Google CoLab (use TensorFlow 1.x)\n", "%tensorflow_version 1.x\n", "from google.colab import drive\n", "drive.mount('/content/drive', force_remount=True)"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "icRPLmPKtCf_"}, "source": ["Next, clone StyleGAN2 from GitHub."]}, {"cell_type": "code", "execution_count": 0, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 85}, "colab_type": "code", "id": "tB0TryzptCf_", "outputId": "1f941bb7-aba1-454f-bee2-ac7501f75a12"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Cloning into 'stylegan2'...\n", "remote: Enumerating objects: 88, done.\u001b[K\n", "remote: Total 88 (delta 0), reused 0 (delta 0), pack-reused 88\u001b[K\n", "Unpacking objects: 100% (88/88), done.\n"]}], "source": ["!git clone https://github.com/NVlabs/stylegan2.git"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "s1Sh0xmOtCgC"}, "source": ["Verify that StyleGAN has been cloned."]}, {"cell_type": "code", "execution_count": 0, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 85}, "colab_type": "code", "id": "wewBEme5tCgD", "outputId": "6f56b745-85b4-452f-840f-032a023f1776"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["dataset_tool.py  LICENSE.txt\t\t README.md\t   run_training.py\n", "dnnlib\t\t metrics\t\t run_generator.py  test_nvcc.cu\n", "Dockerfile\t pretrained_networks.py  run_metrics.py    training\n", "docs\t\t projector.py\t\t run_projector.py\n"]}], "source": ["!ls /content/stylegan2/"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "e4WrIU6F3Iwe"}, "source": ["# Run StyleGan2 From Command Line"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "GQGFXRI0tCgG"}, "source": ["Add the StyleGAN folder to Python so that you can import it.  The code below is based on code from NVidia. This actually generates your images."]}, {"cell_type": "code", "execution_count": 0, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 578}, "colab_type": "code", "id": "Wn_lpC_p-4ag", "outputId": "8cdf716d-a2a9-43ac-8acb-32d1c2e2e074"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Local submit - run_dir: results/00000-generate-images\n", "dnnlib: Running run_generator.generate_images() on localhost...\n", "Loading networks from \"gdrive:networks/stylegan2-ffhq-config-f.pkl\"...\n", "Downloading http://d36zk2xti64re0.cloudfront.net/stylegan2/networks/stylegan2-ffhq-config-f.pkl ... done\n", "Setting up TensorFlow plugin \"fused_bias_act.cu\": Preprocessing... Compiling... Loading... Done.\n", "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Preprocessing... Compiling... Loading... Done.\n", "Generating image for seed 6600 (0/26) ...\n", "Generating image for seed 6601 (1/26) ...\n", "Generating image for seed 6602 (2/26) ...\n", "Generating image for seed 6603 (3/26) ...\n", "Generating image for seed 6604 (4/26) ...\n", "Generating image for seed 6605 (5/26) ...\n", "Generating image for seed 6606 (6/26) ...\n", "Generating image for seed 6607 (7/26) ...\n", "Generating image for seed 6608 (8/26) ...\n", "Generating image for seed 6609 (9/26) ...\n", "Generating image for seed 6610 (10/26) ...\n", "Generating image for seed 6611 (11/26) ...\n", "Generating image for seed 6612 (12/26) ...\n", "Generating image for seed 6613 (13/26) ...\n", "Generating image for seed 6614 (14/26) ...\n", "Generating image for seed 6615 (15/26) ...\n", "Generating image for seed 6616 (16/26) ...\n", "Generating image for seed 6617 (17/26) ...\n", "Generating image for seed 6618 (18/26) ...\n", "Generating image for seed 6619 (19/26) ...\n", "Generating image for seed 6620 (20/26) ...\n", "Generating image for seed 6621 (21/26) ...\n", "Generating image for seed 6622 (22/26) ...\n", "Generating image for seed 6623 (23/26) ...\n", "Generating image for seed 6624 (24/26) ...\n", "Generating image for seed 6625 (25/26) ...\n", "dnnlib: Finished run_generator.generate_images() in 1m 28s.\n"]}], "source": ["!python /content/stylegan2/run_generator.py generate-images \\\n", "    --network=gdrive:networks/stylegan2-ffhq-config-f.pkl \\\n", "  --seeds=6600-6625 --truncation-psi=0.5"]}, {"cell_type": "code", "execution_count": 0, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 136}, "colab_type": "code", "id": "UnrUF5L1_3UI", "outputId": "c319d5b6-376e-437f-bf54-8a936a4bc2d4"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["_finished.txt  seed6604.png  seed6611.png  seed6618.png  seed6625.png\n", "log.txt        seed6605.png  seed6612.png  seed6619.png  submit_config.pkl\n", "run.txt        seed6606.png  seed6613.png  seed6620.png  submit_config.txt\n", "seed6600.png   seed6607.png  seed6614.png  seed6621.png\n", "seed6601.png   seed6608.png  seed6615.png  seed6622.png\n", "seed6602.png   seed6609.png  seed6616.png  seed6623.png\n", "seed6603.png   seed6610.png  seed6617.png  seed6624.png\n"]}], "source": ["!ls /content/results/00000-generate-images"]}, {"cell_type": "code", "execution_count": 0, "metadata": {"colab": {}, "colab_type": "code", "id": "3rh5faG6AOFA"}, "outputs": [], "source": ["cp /content/results/00000-generate-images/* /content/drive/My\\ Drive/projects/stylegan2"]}, {"cell_type": "code", "execution_count": 10, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 204}, "colab_type": "code", "id": "U9YXGHyRE7aH", "outputId": "1d0ae1a8-a785-4937-e9ea-d0abcb2d8025"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Local submit - run_dir: results/00001-style-mixing-example\n", "dnnlib: Running run_generator.style_mixing_example() on localhost...\n", "Loading networks from \"gdrive:networks/stylegan2-ffhq-config-f.pkl\"...\n", "Setting up TensorFlow plugin \"fused_bias_act.cu\": Preprocessing... Loading... Done.\n", "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Preprocessing... Loading... Done.\n", "Generating W vectors...\n", "Generating images...\n", "Generating style-mixed images...\n", "Saving images...\n", "Saving image grid...\n", "dnnlib: Finished run_generator.style_mixing_example() in 46s.\n"]}], "source": ["!python /content/stylegan2/run_generator.py style-mixing-example \\\n", "    --network=gdrive:networks/stylegan2-ffhq-config-f.pkl \\\n", "  --row-seeds=85,100,75,458,1500 --col-seeds=55,821,1789,293 --truncation-psi=1.0"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "D92Md-Hw3eVA"}, "source": ["# Run StyleGAN2 From Python Code\n", "\n", "Add the StyleGAN folder to Python so that you can import it.  The code below is based on code from NVidia. This actually generates your images."]}, {"cell_type": "code", "execution_count": 0, "metadata": {"colab": {}, "colab_type": "code", "id": "UgMm1sSutCgH"}, "outputs": [], "source": ["import sys\n", "sys.path.insert(0, \"/content/stylegan2\")\n", "\n", "import dnnlib"]}, {"cell_type": "code", "execution_count": 14, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 374}, "colab_type": "code", "id": "yZcFAjaz3mw1", "outputId": "470cf400-80a6-42b6-8a5c-0463e5e36453"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Loading networks from \"gdrive:networks/stylegan2-ffhq-config-f.pkl\"...\n", "Generating image for seed 0/20 ...\n", "Generating image for seed 1/20 ...\n", "Generating image for seed 2/20 ...\n", "Generating image for seed 3/20 ...\n", "Generating image for seed 4/20 ...\n", "Generating image for seed 5/20 ...\n", "Generating image for seed 6/20 ...\n", "Generating image for seed 7/20 ...\n", "Generating image for seed 8/20 ...\n", "Generating image for seed 9/20 ...\n", "Generating image for seed 10/20 ...\n", "Generating image for seed 11/20 ...\n", "Generating image for seed 12/20 ...\n", "Generating image for seed 13/20 ...\n", "Generating image for seed 14/20 ...\n", "Generating image for seed 15/20 ...\n", "Generating image for seed 16/20 ...\n", "Generating image for seed 17/20 ...\n", "Generating image for seed 18/20 ...\n", "Generating image for seed 19/20 ...\n"]}], "source": ["# Copyright (c) 2019, NVIDIA Corporation. All rights reserved.\n", "#\n", "# This work is made available under the Nvidia Source Code License-NC.\n", "# To view a copy of this license, visit\n", "# https://nvlabs.github.io/stylegan2/license.html\n", "\n", "import argparse\n", "import numpy as np\n", "import PIL.Image\n", "import dnnlib\n", "import dnnlib.tflib as tflib\n", "import re\n", "import sys\n", "\n", "import pretrained_networks\n", "\n", "#----------------------------------------------------------------------------\n", "\n", "def expand_seed(seeds, vector_size):\n", "  result = []\n", "\n", "  for seed in seeds:\n", "    rnd = np.random.RandomState(seed)\n", "    result.append( rnd.randn(1, vector_size) ) \n", "  return result\n", "\n", "def generate_images(Gs, seeds, truncation_psi):\n", "    noise_vars = [var for name, var in Gs.components.synthesis.vars.items() \\\n", "                  if name.startswith('noise')]\n", "\n", "    Gs_kwargs = dnnlib.EasyDict()\n", "    Gs_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n", "    Gs_kwargs.randomize_noise = False\n", "    if truncation_psi is not None:\n", "        Gs_kwargs.truncation_psi = truncation_psi\n", "\n", "    for seed_idx, seed in enumerate(seeds):\n", "        print('Generating image for seed %d/%d ...' % (seed_idx, len(seeds)))\n", "        rnd = np.random.RandomState()\n", "        tflib.set_vars({var: rnd.randn(*var.shape.as_list()) for var in noise_vars}) # [height, width]\n", "        images = Gs.run(seed, None, **Gs_kwargs) # [minibatch, height, width, channel]\n", "        path = f\"/content/drive/My Drive/projects/stylegan2/image{seed_idx}.png\"\n", "        PIL.Image.fromarray(images[0], 'RGB').save(path)\n", "\n", "def main():\n", "    sc = dnnlib.SubmitConfig()\n", "    sc.num_gpus = 1\n", "    sc.submit_target = dnnlib.SubmitTarget.LOCAL\n", "    sc.local.do_not_copy_source_files = True\n", "    sc.run_dir_root = \"/content/drive/My Drive/projects/stylegan2\"\n", "    sc.run_desc = 'generate-images'\n", "    network_pkl = 'gdrive:networks/stylegan2-ffhq-config-f.pkl'\n", "\n", "    print('Loading networks from \"%s\"...' % network_pkl)\n", "    _G, _D, Gs = pretrained_networks.load_networks(network_pkl)\n", "    vector_size = Gs.input_shape[1:][0]\n", "    seeds = expand_seed( range(8000,8020), vector_size)\n", "    generate_images(Gs, seeds,truncation_psi=0.5)\n", "\n", "#----------------------------------------------------------------------------\n", "\n", "if __name__ == \"__main__\":\n", "    main()\n", "\n", "#----------------------------------------------------------------------------"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "tYxNRMBIKeOP"}, "source": ["## Examining the Latent Vector\n", "\n", "Figure 7.LVEC shows the effects of transforming the latent vector between two images.\n", "\n", "**Figure 7.LVEC: Transforming the Latent Vector**\n", "![GAN](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/gan_progression.png \"GAN\")"]}, {"cell_type": "code", "execution_count": 15, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 51}, "colab_type": "code", "id": "8jJ8prvsy3am", "outputId": "2a36ccbd-7cdb-413c-f538-9a7254b914ef"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Loading networks from \"gdrive:networks/stylegan2-ffhq-config-f.pkl\"...\n", "(1, 512)\n"]}], "source": ["sc = dnnlib.SubmitConfig()\n", "sc.num_gpus = 1\n", "sc.submit_target = dnnlib.SubmitTarget.LOCAL\n", "sc.local.do_not_copy_source_files = True\n", "sc.run_dir_root = \"/content/drive/My Drive/projects/stylegan2\"\n", "sc.run_desc = 'generate-images'\n", "network_pkl = 'gdrive:networks/stylegan2-ffhq-config-f.pkl'\n", "\n", "print('Loading networks from \"%s\"...' % network_pkl)\n", "_G, _D, Gs = pretrained_networks.load_networks(network_pkl)\n", "vector_size = Gs.input_shape[1:][0]\n", "# range(8192,8300)\n", "seeds = expand_seed( [8192+1,8192+9], vector_size)\n", "#generate_images(Gs, seeds,truncation_psi=0.5)\n", "print(seeds[0].shape)"]}, {"cell_type": "code", "execution_count": 16, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 1000}, "colab_type": "code", "id": "7sUD8c5JCfkg", "outputId": "7b26aff1-81f8-4940-960b-700d86f1f4df"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Generating image for seed 0/300 ...\n", "Generating image for seed 1/300 ...\n", "Generating image for seed 2/300 ...\n", "Generating image for seed 3/300 ...\n", "Generating image for seed 4/300 ...\n", "Generating image for seed 5/300 ...\n", "Generating image for seed 6/300 ...\n", "Generating image for seed 7/300 ...\n", "Generating image for seed 8/300 ...\n", "Generating image for seed 9/300 ...\n", "Generating image for seed 10/300 ...\n", "Generating image for seed 11/300 ...\n", "Generating image for seed 12/300 ...\n", "Generating image for seed 13/300 ...\n", "Generating image for seed 14/300 ...\n", "Generating image for seed 15/300 ...\n", "Generating image for seed 16/300 ...\n", "Generating image for seed 17/300 ...\n", "Generating image for seed 18/300 ...\n", "Generating image for seed 19/300 ...\n", "Generating image for seed 20/300 ...\n", "Generating image for seed 21/300 ...\n", "Generating image for seed 22/300 ...\n", "Generating image for seed 23/300 ...\n", "Generating image for seed 24/300 ...\n", "Generating image for seed 25/300 ...\n", "Generating image for seed 26/300 ...\n", "Generating image for seed 27/300 ...\n", "Generating image for seed 28/300 ...\n", "Generating image for seed 29/300 ...\n", "Generating image for seed 30/300 ...\n", "Generating image for seed 31/300 ...\n", "Generating image for seed 32/300 ...\n", "Generating image for seed 33/300 ...\n", "Generating image for seed 34/300 ...\n", "Generating image for seed 35/300 ...\n", "Generating image for seed 36/300 ...\n", "Generating image for seed 37/300 ...\n", "Generating image for seed 38/300 ...\n", "Generating image for seed 39/300 ...\n", "Generating image for seed 40/300 ...\n", "Generating image for seed 41/300 ...\n", "Generating image for seed 42/300 ...\n", "Generating image for seed 43/300 ...\n", "Generating image for seed 44/300 ...\n", "Generating image for seed 45/300 ...\n", "Generating image for seed 46/300 ...\n", "Generating image for seed 47/300 ...\n", "Generating image for seed 48/300 ...\n", "Generating image for seed 49/300 ...\n", "Generating image for seed 50/300 ...\n", "Generating image for seed 51/300 ...\n", "Generating image for seed 52/300 ...\n", "Generating image for seed 53/300 ...\n", "Generating image for seed 54/300 ...\n", "Generating image for seed 55/300 ...\n", "Generating image for seed 56/300 ...\n", "Generating image for seed 57/300 ...\n", "Generating image for seed 58/300 ...\n", "Generating image for seed 59/300 ...\n", "Generating image for seed 60/300 ...\n", "Generating image for seed 61/300 ...\n", "Generating image for seed 62/300 ...\n", "Generating image for seed 63/300 ...\n", "Generating image for seed 64/300 ...\n", "Generating image for seed 65/300 ...\n", "Generating image for seed 66/300 ...\n", "Generating image for seed 67/300 ...\n", "Generating image for seed 68/300 ...\n", "Generating image for seed 69/300 ...\n", "Generating image for seed 70/300 ...\n", "Generating image for seed 71/300 ...\n", "Generating image for seed 72/300 ...\n", "Generating image for seed 73/300 ...\n", "Generating image for seed 74/300 ...\n", "Generating image for seed 75/300 ...\n", "Generating image for seed 76/300 ...\n", "Generating image for seed 77/300 ...\n", "Generating image for seed 78/300 ...\n", "Generating image for seed 79/300 ...\n", "Generating image for seed 80/300 ...\n", "Generating image for seed 81/300 ...\n", "Generating image for seed 82/300 ...\n", "Generating image for seed 83/300 ...\n", "Generating image for seed 84/300 ...\n", "Generating image for seed 85/300 ...\n", "Generating image for seed 86/300 ...\n", "Generating image for seed 87/300 ...\n", "Generating image for seed 88/300 ...\n", "Generating image for seed 89/300 ...\n", "Generating image for seed 90/300 ...\n", "Generating image for seed 91/300 ...\n", "Generating image for seed 92/300 ...\n", "Generating image for seed 93/300 ...\n", "Generating image for seed 94/300 ...\n", "Generating image for seed 95/300 ...\n", "Generating image for seed 96/300 ...\n", "Generating image for seed 97/300 ...\n", "Generating image for seed 98/300 ...\n", "Generating image for seed 99/300 ...\n", "Generating image for seed 100/300 ...\n", "Generating image for seed 101/300 ...\n", "Generating image for seed 102/300 ...\n", "Generating image for seed 103/300 ...\n", "Generating image for seed 104/300 ...\n", "Generating image for seed 105/300 ...\n", "Generating image for seed 106/300 ...\n", "Generating image for seed 107/300 ...\n", "Generating image for seed 108/300 ...\n", "Generating image for seed 109/300 ...\n", "Generating image for seed 110/300 ...\n", "Generating image for seed 111/300 ...\n", "Generating image for seed 112/300 ...\n", "Generating image for seed 113/300 ...\n", "Generating image for seed 114/300 ...\n", "Generating image for seed 115/300 ...\n", "Generating image for seed 116/300 ...\n", "Generating image for seed 117/300 ...\n", "Generating image for seed 118/300 ...\n", "Generating image for seed 119/300 ...\n", "Generating image for seed 120/300 ...\n", "Generating image for seed 121/300 ...\n", "Generating image for seed 122/300 ...\n", "Generating image for seed 123/300 ...\n", "Generating image for seed 124/300 ...\n", "Generating image for seed 125/300 ...\n", "Generating image for seed 126/300 ...\n", "Generating image for seed 127/300 ...\n", "Generating image for seed 128/300 ...\n", "Generating image for seed 129/300 ...\n", "Generating image for seed 130/300 ...\n", "Generating image for seed 131/300 ...\n", "Generating image for seed 132/300 ...\n", "Generating image for seed 133/300 ...\n", "Generating image for seed 134/300 ...\n", "Generating image for seed 135/300 ...\n", "Generating image for seed 136/300 ...\n", "Generating image for seed 137/300 ...\n", "Generating image for seed 138/300 ...\n", "Generating image for seed 139/300 ...\n", "Generating image for seed 140/300 ...\n", "Generating image for seed 141/300 ...\n", "Generating image for seed 142/300 ...\n", "Generating image for seed 143/300 ...\n", "Generating image for seed 144/300 ...\n", "Generating image for seed 145/300 ...\n", "Generating image for seed 146/300 ...\n", "Generating image for seed 147/300 ...\n", "Generating image for seed 148/300 ...\n", "Generating image for seed 149/300 ...\n", "Generating image for seed 150/300 ...\n", "Generating image for seed 151/300 ...\n", "Generating image for seed 152/300 ...\n", "Generating image for seed 153/300 ...\n", "Generating image for seed 154/300 ...\n", "Generating image for seed 155/300 ...\n", "Generating image for seed 156/300 ...\n", "Generating image for seed 157/300 ...\n", "Generating image for seed 158/300 ...\n", "Generating image for seed 159/300 ...\n", "Generating image for seed 160/300 ...\n", "Generating image for seed 161/300 ...\n", "Generating image for seed 162/300 ...\n", "Generating image for seed 163/300 ...\n", "Generating image for seed 164/300 ...\n", "Generating image for seed 165/300 ...\n", "Generating image for seed 166/300 ...\n", "Generating image for seed 167/300 ...\n", "Generating image for seed 168/300 ...\n", "Generating image for seed 169/300 ...\n", "Generating image for seed 170/300 ...\n", "Generating image for seed 171/300 ...\n", "Generating image for seed 172/300 ...\n", "Generating image for seed 173/300 ...\n", "Generating image for seed 174/300 ...\n", "Generating image for seed 175/300 ...\n", "Generating image for seed 176/300 ...\n", "Generating image for seed 177/300 ...\n", "Generating image for seed 178/300 ...\n", "Generating image for seed 179/300 ...\n", "Generating image for seed 180/300 ...\n", "Generating image for seed 181/300 ...\n", "Generating image for seed 182/300 ...\n", "Generating image for seed 183/300 ...\n", "Generating image for seed 184/300 ...\n", "Generating image for seed 185/300 ...\n", "Generating image for seed 186/300 ...\n", "Generating image for seed 187/300 ...\n", "Generating image for seed 188/300 ...\n", "Generating image for seed 189/300 ...\n", "Generating image for seed 190/300 ...\n", "Generating image for seed 191/300 ...\n", "Generating image for seed 192/300 ...\n", "Generating image for seed 193/300 ...\n", "Generating image for seed 194/300 ...\n", "Generating image for seed 195/300 ...\n", "Generating image for seed 196/300 ...\n", "Generating image for seed 197/300 ...\n", "Generating image for seed 198/300 ...\n", "Generating image for seed 199/300 ...\n", "Generating image for seed 200/300 ...\n", "Generating image for seed 201/300 ...\n", "Generating image for seed 202/300 ...\n", "Generating image for seed 203/300 ...\n", "Generating image for seed 204/300 ...\n", "Generating image for seed 205/300 ...\n", "Generating image for seed 206/300 ...\n", "Generating image for seed 207/300 ...\n", "Generating image for seed 208/300 ...\n", "Generating image for seed 209/300 ...\n", "Generating image for seed 210/300 ...\n", "Generating image for seed 211/300 ...\n", "Generating image for seed 212/300 ...\n", "Generating image for seed 213/300 ...\n", "Generating image for seed 214/300 ...\n", "Generating image for seed 215/300 ...\n", "Generating image for seed 216/300 ...\n", "Generating image for seed 217/300 ...\n", "Generating image for seed 218/300 ...\n", "Generating image for seed 219/300 ...\n", "Generating image for seed 220/300 ...\n", "Generating image for seed 221/300 ...\n", "Generating image for seed 222/300 ...\n", "Generating image for seed 223/300 ...\n", "Generating image for seed 224/300 ...\n", "Generating image for seed 225/300 ...\n", "Generating image for seed 226/300 ...\n", "Generating image for seed 227/300 ...\n", "Generating image for seed 228/300 ...\n", "Generating image for seed 229/300 ...\n", "Generating image for seed 230/300 ...\n", "Generating image for seed 231/300 ...\n", "Generating image for seed 232/300 ...\n", "Generating image for seed 233/300 ...\n", "Generating image for seed 234/300 ...\n", "Generating image for seed 235/300 ...\n", "Generating image for seed 236/300 ...\n", "Generating image for seed 237/300 ...\n", "Generating image for seed 238/300 ...\n", "Generating image for seed 239/300 ...\n", "Generating image for seed 240/300 ...\n", "Generating image for seed 241/300 ...\n", "Generating image for seed 242/300 ...\n", "Generating image for seed 243/300 ...\n", "Generating image for seed 244/300 ...\n", "Generating image for seed 245/300 ...\n", "Generating image for seed 246/300 ...\n", "Generating image for seed 247/300 ...\n", "Generating image for seed 248/300 ...\n", "Generating image for seed 249/300 ...\n", "Generating image for seed 250/300 ...\n", "Generating image for seed 251/300 ...\n", "Generating image for seed 252/300 ...\n", "Generating image for seed 253/300 ...\n", "Generating image for seed 254/300 ...\n", "Generating image for seed 255/300 ...\n", "Generating image for seed 256/300 ...\n", "Generating image for seed 257/300 ...\n", "Generating image for seed 258/300 ...\n", "Generating image for seed 259/300 ...\n", "Generating image for seed 260/300 ...\n", "Generating image for seed 261/300 ...\n", "Generating image for seed 262/300 ...\n", "Generating image for seed 263/300 ...\n", "Generating image for seed 264/300 ...\n", "Generating image for seed 265/300 ...\n", "Generating image for seed 266/300 ...\n", "Generating image for seed 267/300 ...\n", "Generating image for seed 268/300 ...\n", "Generating image for seed 269/300 ...\n", "Generating image for seed 270/300 ...\n", "Generating image for seed 271/300 ...\n", "Generating image for seed 272/300 ...\n", "Generating image for seed 273/300 ...\n", "Generating image for seed 274/300 ...\n", "Generating image for seed 275/300 ...\n", "Generating image for seed 276/300 ...\n", "Generating image for seed 277/300 ...\n", "Generating image for seed 278/300 ...\n", "Generating image for seed 279/300 ...\n", "Generating image for seed 280/300 ...\n", "Generating image for seed 281/300 ...\n", "Generating image for seed 282/300 ...\n", "Generating image for seed 283/300 ...\n", "Generating image for seed 284/300 ...\n", "Generating image for seed 285/300 ...\n", "Generating image for seed 286/300 ...\n", "Generating image for seed 287/300 ...\n", "Generating image for seed 288/300 ...\n", "Generating image for seed 289/300 ...\n", "Generating image for seed 290/300 ...\n", "Generating image for seed 291/300 ...\n", "Generating image for seed 292/300 ...\n", "Generating image for seed 293/300 ...\n", "Generating image for seed 294/300 ...\n", "Generating image for seed 295/300 ...\n", "Generating image for seed 296/300 ...\n", "Generating image for seed 297/300 ...\n", "Generating image for seed 298/300 ...\n", "Generating image for seed 299/300 ...\n"]}], "source": ["# 8192+1,8192+9\n", "\n", "STEPS = 300\n", "diff = seeds[1] - seeds[0]\n", "step = diff / STEPS\n", "current = seeds[0].copy()\n", "\n", "seeds2 = []\n", "for i in range(STEPS):\n", "  seeds2.append(current)\n", "  current = current + step\n", "\n", "generate_images(Gs, seeds2,truncation_psi=0.5)"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "6fC8Sl-B9cx2"}, "source": ["ffmpeg -r 30 -i image%d.png -vcodec mpeg4 -y movie.mp4"]}], "metadata": {"anaconda-cloud": {}, "kernelspec": {"display_name": "Python 3.6 (tensorflow)", "language": "python", "name": "tensorflow"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.5"}}, "nbformat": 4, "nbformat_minor": 1}